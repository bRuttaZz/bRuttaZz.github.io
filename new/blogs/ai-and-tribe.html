<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Projects | bRuttaZz</title>
        <!-- Using Roboto Mono font as requested -->
        <link
            href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;600&display=swap"
            rel="stylesheet"
        />
        <link
            href="https://cdn.jsdelivr.net/npm/@mdi/font@7.4.47/css/materialdesignicons.min.css"
            rel="stylesheet"
            crossorigin="anonymous"
        />
        <link href="../style.css" rel="stylesheet" />
    </head>
    <body>
        <div class="header">
            <!-- Placeholder to help center the nav links relative to the button -->
            <div class="header-side-btn"></div>

            <!-- Minimal Page Navigation (Centered) -->
            <div class="nav-center-wrapper">
                <nav>
                    <a href="/" class="nav-link">about</a>
                    <a href="/projects.html" class="nav-link">projects</a>
                    <a href="/blogs.html" class="nav-link">blogs</a>
                </nav>
            </div>
            <!-- Theme Switch Button (Top Right) -->
            <div class="header-side-btn header-btn theme-switcher d-none">
                <span class="mdi mdi-brightness-6 fs-5"></span>
            </div>
        </div>

        <!-- Main Centered Content -->
        <div class="main-content">
            <div class="text-container">
                <!-- content  -->
                <!-- ...  -->

                <!-- blog portion  -->
                <div class="blog-content">
                    <div>
                        <span class="blog-date-badge"
                            >Last edited: 26 Feb 2025</span
                        >
                    </div>

                    <!--Render engine generated content -->
                    <div class="generated-content">
                        <h1>Picking Sides!</h1>
                        <p>
                            <small
                                >⚠️ Caution: The following content is written
                                within the seclusion of my thoughts so you might
                                encounter more opinions than facts.</small
                            >
                        </p>
                        <center>
                            <img
                                src="/assets/blog/1.ai-and-tribe/spiderman-picking-side.jpg"
                                width="90%"
                                alt="spiderman picking sides"
                            />
                            <small>
                                <p>
                                    <strong>[Credits]</strong> Movie: Spider-man
                                    | Scene: The Women You Love Or Helpless
                                    Children
                                </p>
                            </small>
                        </center>
                        <h3>Problem 1</h3>
                        <p>
                            <strong>Context</strong>: "Suppose you are
                            Spider-Man/Spider-Woman. In front of you, there's a
                            cat on one side and a lady on the other. You have to
                            save one, and the other will die! And most
                            importantly, unlike the traditional Spider-Man
                            movies we've seen, here you can only save one."
                        </p>
                        <p>
                            <strong>Question</strong>: Which side are you going
                            to choose?
                        </p>
                        <p>
                            I know the situation sounds a bit cold. For an
                            easier read, let's say the one you can't save won’t
                            actually die, but instead, they'll be asked to do 10
                            jumping jacks in slow motion.
                        </p>
                        <p>Sounds good? Fine!</p>
                        <p>
                            Now, let's try to address the question. If it were
                            me, just like most non-cat-moms/cat-dads would
                            probably choose, I’d save the lady (for sure!).
                        </p>
                        <p>
                            Why? I don't know, it just seems natural/intuitive.
                            Maybe there are several reasons:
                        </p>
                        <ol>
                            <li>
                                I can relate to the lady's pain more than the
                                cat's.
                            </li>
                            <li>
                                A cat doesn't have the complex relationships,
                                intelligence, and emotions that a human does, so
                                it seems more "just" to save the human. (In
                                comparison.)
                            </li>
                            <li>...</li>
                        </ol>
                        <p>
                            Let me explain this simple solution we've arrived at
                            based on the idea of
                            <strong>"Tribe selection"</strong>. <br />When we're
                            in a crisis where we need to choose between two
                            things, we usually do a quick analysis to pick the
                            side that aligns most closely with our tribe
                            mentality. Here, we've teamed up with the lady
                            because she is a more suitable member of our tribe,
                            in comparison. <br />Why do we behave like this?
                            Because all our viewpoints, our laws, our sense of
                            right and wrong, are bound to this tribe mentality
                            of ours. That's why, sometimes, it's easy to choose
                            sides in a war between soldiers—if one of them is
                            serving our country, it often doesn’t even matter
                            whether both sides are fighting for the same goal
                            (maybe just expanding or holding onto their land) (I
                            admit, the example is super simplified, but you got
                            the point).
                        </p>
                        <p>
                            Think about it—tribe mentality can be seen in a lot
                            of modern species that live in colonies. Surely,
                            we’re not an exception. But the interesting thing is
                            that our tribe mentality is expanding. Let me
                            explain...
                        </p>
                        <h3>Problem 2</h3>
                        <p>
                            <strong>Context</strong>: "Again, you are
                            Spider-Man/Spider-Woman. This time, instead of
                            choosing between a cat and a lady, you have to save
                            one person from ethnicity "X" and another from
                            ethnicity "Y". You can save only one of them."
                        </p>
                        <p>
                            <strong>Question</strong>: Which side are you going
                            to choose? Or which tribe are you going to pick?
                        </p>
                        <p>Seems hard, right?</p>
                        <p>
                            Maybe not... If we were to travel back in time, at
                            least for most of the population, the answer might
                            seem easy if we can tweak the values of "X" and "Y".
                            Let’s say we go to the Victorian era, just about 120
                            years ago. The answer might vary depending on who
                            you ask, right? The so-called "elite" ethnicity
                            might choose someone similar from either X or Y. If
                            I’m not wrong, slavery was officially ended in the
                            mid-19th century (on paper). To quote a local
                            example, in Kerala, about just one generation ago
                            (around ~100 years ago), only about 1% of the
                            population was able to enter temples.
                        </p>
                        <p>
                            I admit, things may not be perfect today, but things
                            have changed for sure. <br />Coming back to the
                            second problem, here in 2025, it’s somewhat hard for
                            us (at least for most of us) to choose between these
                            two given options.
                        </p>
                        <p>Why?</p>
                        <ol>
                            <li>
                                We know, despite their ethnicity, both of them
                                are human.
                            </li>
                            <li>
                                They share similar brains, with similar thought
                                systems and emotions.
                            </li>
                            <li>Both of them will feel the same emotions...</li>
                            <li>...</li>
                        </ol>
                        <p>
                            So how were we able to choose more easily in the
                            past? I don’t know, maybe we were more "dumb" back
                            then, collectively speaking... (For now, I’m not
                            interested in wandering around those "dumb"
                            reasons.)
                        </p>
                        <p>
                            Here the interesting point is that we are evolving,
                            and so is our tribe mentality. <br />How? I don’t
                            know. Maybe because, as a whole, humanity is getting
                            more comfy life options than before, which might
                            have cope us with the privilege to think about
                            others more than our ancestors did in the past...
                        </p>
                        <p>
                            Anyway, it's true that
                            <strong>our tribe mentality is expanding</strong>.
                            For example, over time, taking humanity as a whole,
                            our "civilized" mentality has evolved. The
                            <a
                                href="https://www.cafonline.org/docs/default-source/inside-giving/wgi/wgi_2024_report.pdf"
                                >World Giving Index</a
                            >
                            has been increasing over time, our
                            <a
                                href="https://www.rspca.org.uk/whatwedo/latest/kindnessindex/annual/report2024"
                                >Animal Kindness Index</a
                            >
                            is getting better, and most of our unofficial
                            kindness indices are
                            <a
                                href="https://helgas.com.au/sites/default/files/2021-08/Helgas_The%20Works_Kindness%20in%20Australia_McCrindle_13.8.21.FINAL_.pdf"
                                >increasing</a
                            >. In general, as a species, we are becoming kinder
                            than our previous generations, and this trend may
                            continue. <br />Our "tribe mentality" IS
                            expanding...
                        </p>
                        <p>
                            That said, I admit, the implications of
                            <strong>Problem No. 2</strong> are a bit disturbing,
                            as we still have a lot to improve. All of us know
                            that, instead of ethnicity, if we were to put two
                            people from different countries, religions, genders,
                            races, etc., some of us might find this problem
                            easier to solve... And that is surely a dangerous
                            fact!
                        </p>
                        <p>
                            <strong>In practical terms</strong>, today (in
                            2025), there’s no real benefit in expanding this
                            thought experiment beyond this point. We’re not yet
                            able to accommodate all the people on Earth—across
                            different countries, religions, ideologies, genders,
                            races, habitats, accessibilities, ages, and so
                            on—into a single tribe of
                            <em>Homo sapiens sapiens</em>.
                        </p>
                        <h4>Anywho,</h4>
                        <p>
                            recently I got to spend an amazing weekend with my
                            old colleagues at a resort. All of us were happy,
                            like-minded, and accompanied by some drinks (ranging
                            from vodka to apple juice). That night, we had this
                            privilege of discussing and imagining a
                            fast-forwarded world where all of humanity has
                            accepted us into a single tribe. In that utopia, we
                            were struck with a (seemingly) crazy question. The
                            rest of this blog takes place in that hypothetical
                            world...
                        </p>
                        <p>
                            <strong>Question</strong>: Suppose we have an
                            advanced AI that can reason and talk like we humans
                            do... and suppose I’ve been chatting with it for a
                            while, and suddenly, I feel tired. Is it okay for me
                            to press the kill switch? <br />What if the AI was
                            actually thinking? What if it had been feeling alive
                            from the moment I invoked it? What stance should our
                            expanded tribe mentality take?
                        </p>
                        <p>
                            It may sound easy. We created the application; we
                            know it merely generates words using the "ones and
                            zeros" we feed into the machine...
                        </p>
                        <p>Is it?</p>
                        <p>
                            Now, imagine that the AI has become so advanced that
                            it can mimic our brain's neural network model, or
                            even exceed the capabilities of that model...
                            <br />After all, our brains do the same thing,
                            right? In between responding to surrounding stimuli,
                            we experience this feeling of aliveness, of
                            consciousness. <br />What if the AI has evolved to
                            the point where it has developed reasoning abilities
                            like ours (or even better)? <br />What if, while
                            figuring out the answer to our question, it's also
                            developing a sense of consciousness?
                        </p>
                        <p>
                            I mean,
                            <strong
                                >if we—an evolutionarily formed chemical
                                system—can feel consciousness by doing the exact
                                same processes (passing electric signals through
                                neurons, gradually trained according to
                                surrounding stimuli), then an advanced
                                technology mimicking or modeling the same should
                                also be able to feel it at some point, right?
                                (Unless, of course, you believe in souls, gods,
                                or Bigfoots).</strong
                            >
                            This implies that such an era is possible. And our
                            question is set at the beginning of such an era.
                            <br />In-addition, since it's trained on human data,
                            we can assume it should understand the concepts of
                            love and empathy.
                        </p>
                        <p>
                            What about now? Does the question seem a bit
                            difficult? Maybe let's start by applying our biased
                            Spider-Man/Spider-Woman analogy.
                        </p>
                        <h3>Problem 3</h3>
                        <p>
                            <strong>Context</strong>: "You are
                            Spider-Man/Spider-Woman. On one side, there is an AI
                            system (capable of thinking like us and having
                            consciousness), and on the other side, there is a
                            cat. You can save one of them. The other will suffer
                            (by doing 10 jumping jacks in slow motion)."
                        </p>
                        <p>
                            <strong>Question</strong>: Whom will you choose?
                            Which one is closest to your tribe? Which decision
                            is more just in your tribe mentality?
                        </p>
                        <p>Confused? (I’m confused for sure.)</p>
                        <p>
                            Say you saved the cat. The justifications would be:
                        </p>
                        <ol>
                            <li>
                                Cat-dads and cat-moms will love you for that.
                            </li>
                            <li>
                                You selected a physically similar life form
                                compared to you.
                            </li>
                        </ol>
                        <p>What about saving the AI system?</p>
                        <ol>
                            <li>
                                You saved a system with more complex
                                consciousness.
                            </li>
                            <li>
                                It has more advanced intelligence and thoughts,
                                similar to ours, in comparison to a cat.
                            </li>
                        </ol>
                        <p>
                            Still confusing? <br />Think of it this way: Why do
                            we choose to obey the rules and act justly in our
                            tribe? So that another member of our tribe can trust
                            that we’ll choose them over a less intelligent or
                            complex being, like a cat. <br />So ideally, what
                            should the other individuals in our broad tribe feel
                            when we choose a cat over something that can
                            actually think and has consciousness and emotions
                            like we do?
                        </p>
                        <p>
                            In other words, in our expanded tribe, we’ll be
                            accommodating all of <em>Homo sapiens</em>, right?
                            This might include people with completely different
                            physical states and abilities. But we cannot compare
                            them, because we know: all of them will be feeling
                            and having consciousness just like we do.
                            <strong>The idea of empathy</strong>. In this
                            context, the difference in physical states and
                            abilities doesn’t matter, as it’s not something they
                            chose.
                        </p>
                        <p>
                            Now, let’s compare this to the case of the complex
                            AI. As quoted in the movie
                            <a
                                href="https://en.wikipedia.org/wiki/The_Imitation_Game"
                                >Imitation Game</a
                            >, the machines might be thinking via electrical
                            flow through copper and silicon, but we cannot deny
                            the fact that they are thinking and have
                            consciousness..
                        </p>
                        <p>
                            Which one aligns more with our tribe? Which is more
                            just according to our tribe’s laws?
                        </p>
                        <p>
                            What if we go further and had to choose between a
                            human and an AI?
                        </p>
                        <p>
                            But there’s this big catch right? <br />We do all of
                            these tribe things and make empathetic decisions
                            based on our evolutionary biases—like love,
                            affection, etc.—which are hardwired in our DNA and
                            decision-making. Will AI inherit these things?
                        </p>
                        <p>
                            If they learn by observing us, they might pick up
                            these ideas, right? <br />In other words, how do we
                            make a decision if they say they’re having those
                            emotions and ask us to trust them? <br />Can we
                            trust ourselves? <br />What if, in the end, both of
                            us are reflecting the same face of uncertainty?
                        </p>
                        <p>
                            Which one is more trustworthy: a biological black
                            box (our brain) or an electronic black box (their
                            "brain")?
                        </p>
                        <p>
                            <strong
                                >And the implied question is: How big can our
                                tribe grow?</strong
                            >
                        </p>
                        <p>
                            <br /><br />
                            After exhausting our little heads with these
                            questions, we left it there, smiled at each other,
                            filled with love for our little tribe we went to
                            bed.
                            <br /><strong
                                >And it felt good to be human, with all of these
                                evolutionary biases like - love, addiction, and
                                the thirst for storytelling...</strong
                            >
                        </p>
                        <p>
                            Still feeling weird... whenever I’m about to press
                            that stop generation button in the GPTs halfway.
                        </p>
                    </div>
                    <!-- content  -->

                    <link
                        rel="stylesheet"
                        href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/styles/default.min.css"
                    />
                    <style>
                        .hljs {
                            background: var(--hlgs-bg);
                            color: var(--hlgs-text);
                        }
                    </style>
                </div>
            </div>
        </div>
        <script src="../scripts.js" anonymoue></script>
    </body>
    <footer>
        <center>
            <div class="bottom-clause">
                Got any objections to my points? love to hear them. Feel free to
                drop me a mail or ping me on Matrix.
            </div>
            <div><span class="mdi mdi-copyleft"></span> 2025 Agraj P Das</div>
            <div>
                Note: This site was developed and works best in the
                <a href="https://www.firefox.com" class="footer-a"
                    >Firefox browser</a
                >
                (solely personal)
            </div>
        </center>
    </footer>
</html>
